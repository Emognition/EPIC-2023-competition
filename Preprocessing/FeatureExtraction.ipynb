{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fffbea29-d293-40bf-bbfa-0cc53203785b",
   "metadata": {},
   "source": [
    "# Extract features \n",
    "\n",
    "\n",
    "extract some predicting features:\n",
    "1. mean individual level affective features (static)\n",
    "2. mean stimulus level affective features (static)\n",
    "3. mean stimulus level (overtime)\n",
    "\n",
    "\n",
    "\n",
    "*Yiyu Wang 04/08/2023*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d0a8e4-9e54-490d-8c10-f9bf05556691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66f69fb-26a0-4aae-a011-87c323a0aa7b",
   "metadata": {},
   "source": [
    "# subject mean level affective features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "139016b0-e15d-47d5-bf36-3988af7ba060",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scenario = 2\n",
    "\n",
    "if scenario == 2:\n",
    "    folds = [0,1,2,3,4]\n",
    "elif scenario == 3:\n",
    "    folds = [0,1,2,3]\n",
    "elif scenario == 4:\n",
    "    folds = [0,1]\n",
    "# mean participant level:\n",
    "\n",
    "for f in folds:\n",
    "    all_files = glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/fold_{f}/train/annotations/*.csv')\n",
    "    \n",
    "    sub_list = []\n",
    "    video_list = []\n",
    "    for file in all_files:\n",
    "        sub_id = file.split('sub_')[1].split('_vid')[0]\n",
    "        sub_list.append(sub_id)\n",
    "\n",
    "        vid_id = file.split('vid_')[1].split('.csv')[0]\n",
    "        video_list.append(vid_id)\n",
    "\n",
    "    sub_list = np.unique(sub_list)\n",
    "    video_list = np.unique(video_list)\n",
    "\n",
    "    valence = []\n",
    "    arousal = []\n",
    "    mean_sub_v = []\n",
    "    mean_sub_a = []\n",
    "    for s in sub_list:\n",
    "        \n",
    "        for file in glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/fold_{f}/train/annotations/sub_{s}*.csv'):\n",
    "            sub_id = file.split('sub_')[1].split('_vid')[0]\n",
    "\n",
    "\n",
    "            vid_id = file.split('vid_')[1].split('.csv')[0]\n",
    "\n",
    "\n",
    "            this_df = pd.read_csv(file)\n",
    "            valence.append(np.nanmean(this_df.valence))\n",
    "            arousal.append(np.nanmean(this_df.arousal))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        mean_sub_v.append(np.mean(valence))\n",
    "        mean_sub_a.append(np.mean(arousal))\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame({'sub':sub_list, 'mean_valence': mean_sub_v, 'mean_arousal': mean_sub_a}).to_csv(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/fold_{f}/train/mean_subject_affective_features.csv', index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c59a30f-4ab5-4723-b050-a766f00c943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario = 1\n",
    "scenario = 1\n",
    "\n",
    "# mean participant level:\n",
    "\n",
    "\n",
    "all_files = glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/train/annotations/*.csv')\n",
    "\n",
    "sub_list = []\n",
    "video_list = []\n",
    "for file in all_files:\n",
    "    sub_id = file.split('sub_')[1].split('_vid')[0]\n",
    "    sub_list.append(sub_id)\n",
    "\n",
    "    vid_id = file.split('vid_')[1].split('.csv')[0]\n",
    "    video_list.append(vid_id)\n",
    "\n",
    "sub_list = np.unique(sub_list)\n",
    "video_list = np.unique(video_list)\n",
    "\n",
    "valence = []\n",
    "arousal = []\n",
    "mean_sub_v = []\n",
    "mean_sub_a = []\n",
    "\n",
    "for s in sub_list:\n",
    "    for file in glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/train/annotations/sub_{s}*.csv'):\n",
    "        sub_id = file.split('sub_')[1].split('_vid')[0]\n",
    "        vid_id = file.split('vid_')[1].split('.csv')[0]\n",
    "\n",
    "\n",
    "        this_df = pd.read_csv(file)\n",
    "        valence.append(np.nanmean(this_df.valence))\n",
    "        arousal.append(np.nanmean(this_df.arousal))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    mean_sub_v.append(np.mean(valence))\n",
    "    mean_sub_a.append(np.mean(arousal))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'sub':sub_list, 'mean_valence': mean_sub_v, 'mean_arousal': mean_sub_a}).to_csv(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/train/mean_subject_affective_features.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c94170-b13b-4faf-b28c-a10f1037fb47",
   "metadata": {},
   "source": [
    "# stimulus mean level affective features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a72464cc-f475-4c99-b649-3e6f76fcd4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean stimulus:\n",
    "\n",
    "scenario = 4\n",
    "\n",
    "if scenario == 2:\n",
    "    folds = [0,1,2,3,4]\n",
    "elif scenario == 3:\n",
    "    folds = [0,1,2,3]\n",
    "elif scenario == 4:\n",
    "    folds = [0,1]\n",
    "# mean participant level:\n",
    "\n",
    "for f in folds:\n",
    "    all_files = glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/fold_{f}/train/annotations/*.csv')\n",
    "    \n",
    "    sub_list = []\n",
    "    video_list = []\n",
    "    for file in all_files:\n",
    "        sub_id = file.split('sub_')[1].split('_vid')[0]\n",
    "        sub_list.append(sub_id)\n",
    "\n",
    "        vid_id = file.split('vid_')[1].split('.csv')[0]\n",
    "        video_list.append(vid_id)\n",
    "\n",
    "    sub_list = np.unique(sub_list)\n",
    "    video_list = np.unique(video_list)\n",
    "\n",
    "    valence = []\n",
    "    arousal = []\n",
    "    mean_video_v = []\n",
    "    mean_video_a = []\n",
    "    for v in video_list:\n",
    "        \n",
    "        for file in glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/fold_{f}/train/annotations/*vid_{v}.csv'):\n",
    "\n",
    "            this_df = pd.read_csv(file)\n",
    "            valence.append(np.nanmean(this_df.valence))\n",
    "            arousal.append(np.nanmean(this_df.arousal))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "        mean_video_v.append(np.mean(valence))\n",
    "        mean_video_a.append(np.mean(arousal))\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame({'video':video_list, 'mean_valence': mean_video_v, 'mean_arousal': mean_video_a}).to_csv(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/fold_{f}/train/mean_video_affective_features.csv', index=False)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b03a30a3-2962-431e-922a-77bb4000d03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario = 1\n",
    "all_files = glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/train/annotations/*.csv')\n",
    "\n",
    "sub_list = []\n",
    "video_list = []\n",
    "for file in all_files:\n",
    "    sub_id = file.split('sub_')[1].split('_vid')[0]\n",
    "    sub_list.append(sub_id)\n",
    "\n",
    "    vid_id = file.split('vid_')[1].split('.csv')[0]\n",
    "    video_list.append(vid_id)\n",
    "\n",
    "sub_list = np.unique(sub_list)\n",
    "video_list = np.unique(video_list)\n",
    "\n",
    "valence = []\n",
    "arousal = []\n",
    "mean_video_v = []\n",
    "mean_video_a = []\n",
    "for v in video_list:\n",
    "\n",
    "    for file in glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/train/annotations/*vid_{v}.csv'):\n",
    "\n",
    "        this_df = pd.read_csv(file)\n",
    "        valence.append(np.nanmean(this_df.valence))\n",
    "        arousal.append(np.nanmean(this_df.arousal))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    mean_video_v.append(np.mean(valence))\n",
    "    mean_video_a.append(np.mean(arousal))\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'video':video_list, 'mean_valence': mean_video_v, 'mean_arousal': mean_video_a}).to_csv(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/train/mean_video_affective_features.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5e8e8d23-1035-4cfd-b3ac-941a4c6a23eb",
   "metadata": {},
   "source": [
    "# dynamic stimulus mean level (over time) affective features:\n",
    "\n",
    "## Note: not really useful since the same videos are tested on different time segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2577b6fa-4c65-4e5e-9580-61e5aab6b70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario = 3\n",
    "scenario = 4\n",
    "if scenario == 2:\n",
    "    folds = [0,1,2,3,4]\n",
    "elif scenario == 3:\n",
    "    folds = [0,1,2,3]\n",
    "elif scenario == 4:\n",
    "    folds = [0,1]\n",
    "    \n",
    "# mean participant level:\n",
    "\n",
    "for f in folds:\n",
    "    all_files = glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/fold_{f}/train/annotations/*.csv')\n",
    "    \n",
    "    sub_list = []\n",
    "    video_list = []\n",
    "    for file in all_files:\n",
    "        sub_id = file.split('sub_')[1].split('_vid')[0]\n",
    "        sub_list.append(sub_id)\n",
    "\n",
    "        vid_id = file.split('vid_')[1].split('.csv')[0]\n",
    "        video_list.append(vid_id)\n",
    "\n",
    "    sub_list = np.unique(sub_list)\n",
    "    video_list = np.unique(video_list)\n",
    "\n",
    "    dataframes = []\n",
    "    \n",
    "    # get the max length\n",
    "    max_len_list = []\n",
    "    for v in video_list:\n",
    "        # check max_len and fill in:\n",
    "        max_len = 0\n",
    "        for file in glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/fold_{f}/train/annotations/*vid_{v}.csv'):\n",
    "            this_df = pd.read_csv(file)\n",
    "            df_len = len(this_df)\n",
    "            if df_len > max_len:\n",
    "                max_len = df_len\n",
    "        max_len_list.append(max_len) \n",
    "    \n",
    "    # fill in the missing row: \n",
    "    \n",
    "    for idx, v in enumerate(video_list):\n",
    "        valence = []\n",
    "        arousal = []\n",
    "        max_len = max_len_list[idx]\n",
    "        for file in glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/fold_{f}/train/annotations/*vid_{v}.csv'):\n",
    "            this_df = pd.read_csv(file)\n",
    "            df_len = len(this_df)\n",
    "            if df_len < max_len:\n",
    "                missing_rows = max_len - df_len\n",
    "                last_row = this_df.iloc[-1].to_frame().T\n",
    "\n",
    "                for _ in range(missing_rows):\n",
    "                    this_df = this_df.append(last_row, ignore_index=True)\n",
    "            valence.append(np.array(this_df.valence))\n",
    "            arousal.append(np.array(this_df.arousal))\n",
    "\n",
    "\n",
    "        \n",
    "        mean_video_v = np.mean(valence, axis=0)\n",
    "        mean_video_a = np.mean(arousal, axis=0)\n",
    "        \n",
    "        # save to df:\n",
    "        aff_features = pd.DataFrame({'valence': mean_video_v, 'arousal': mean_video_a}).to_csv(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/fold_{f}/train/mean_video-{v}_dynamic_affective_features.csv')\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cc2308ff-a928-4b3c-9513-9629abc7c875",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "scenario == 1\n",
    "\n",
    "all_files = glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/train/annotations/*.csv')\n",
    "\n",
    "sub_list = []\n",
    "video_list = []\n",
    "for file in all_files:\n",
    "    sub_id = file.split('sub_')[1].split('_vid')[0]\n",
    "    sub_list.append(sub_id)\n",
    "\n",
    "    vid_id = file.split('vid_')[1].split('.csv')[0]\n",
    "    video_list.append(vid_id)\n",
    "\n",
    "sub_list = np.unique(sub_list)\n",
    "video_list = np.unique(video_list)\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "# get the max length\n",
    "max_len_list = []\n",
    "for v in video_list:\n",
    "    # check max_len and fill in:\n",
    "    max_len = 0\n",
    "    for file in glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/train/annotations/*vid_{v}.csv'):\n",
    "        this_df = pd.read_csv(file)\n",
    "        df_len = len(this_df)\n",
    "        if df_len > max_len:\n",
    "            max_len = df_len\n",
    "    max_len_list.append(max_len) \n",
    "\n",
    "# fill in the missing row: \n",
    "\n",
    "for idx, v in enumerate(video_list):\n",
    "    valence = []\n",
    "    arousal = []\n",
    "    max_len = max_len_list[idx]\n",
    "    for file in glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/train/annotations/*vid_{v}.csv'):\n",
    "        this_df = pd.read_csv(file)\n",
    "        df_len = len(this_df)\n",
    "        if df_len < max_len:\n",
    "            missing_rows = max_len - df_len\n",
    "            last_row = this_df.iloc[-1].to_frame().T\n",
    "\n",
    "            for _ in range(missing_rows):\n",
    "                this_df = this_df.append(last_row, ignore_index=True)\n",
    "        valence.append(np.array(this_df.valence))\n",
    "        arousal.append(np.array(this_df.arousal))\n",
    "\n",
    "\n",
    "\n",
    "    mean_video_v = np.mean(valence, axis=0)\n",
    "    mean_video_a = np.mean(arousal, axis=0)\n",
    "\n",
    "    # save to df:\n",
    "    aff_features = pd.DataFrame({'valence': mean_video_v, 'arousal': mean_video_a}).to_csv(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/train/mean_video-{v}_dynamic_affective_features.csv')\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e2d0417-5710-49cf-9ca7-473ae7c2ddcf",
   "metadata": {},
   "source": [
    "# Zscore physio features from the preprocessed csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "759fba19-afee-44bb-84fa-e9c4d8f887a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "scenario = 4\n",
    "processed_file_paths = glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/*/*/phys*/*_processed_1hz.csv')\n",
    "for processed_file in processed_file_paths:\n",
    "    \n",
    "\n",
    "    # Load data into a dataframe\n",
    "    df = pd.read_csv(processed_file)  \n",
    "\n",
    "    # Select only the columns to be zscored\n",
    "    cols_to_zscore = [col for col in df.columns if col not in ['sub_num', 'vid_num','vid_mean_val','vid_mean_arousal']]\n",
    "\n",
    "    # Zscore the selected columns\n",
    "    df[cols_to_zscore] = df[cols_to_zscore].apply(zscore)\n",
    "    df = df.fillna(0)\n",
    "    # Save\n",
    "    df.to_csv(processed_file.split('.csv')[0] + '_zscored.csv', index= False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2017fab9-947d-4d19-95da-f2800d68e6d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5914b8-5b2c-4e11-a708-347307172d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
