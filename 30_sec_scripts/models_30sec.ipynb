{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob as glob\n",
    "import numpy as np\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "import pipeline_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns of interest. \n",
    "#Here are the different physio features used in the Machine learning models as regressors\n",
    "\n",
    "fizz_columns_of_interest = [\n",
    "    'PPG_Clean', 'PPG_Rate', 'PPG_Peaks',\n",
    "    'ECG_Rate','ECG_Quality',\n",
    "    'EDA_Clean', 'EDA_Tonic', 'EDA_Phasic', 'SCR_Onsets', 'SCR_Peaks','SCR_Height', 'SCR_Amplitude',\n",
    "    'RSP_Amplitude', 'RSP_Rate',\n",
    "    'corrugator_EMG_Clean',\n",
    "    'corrugator_EMG_Amplitude', 'corrugator_EMG_Activity',\n",
    "    'corrugator_EMG_Onsets', 'corrugator_EMG_Offsets',\n",
    "    'trapezius_EMG_Clean', 'trapezius_EMG_Amplitude',\n",
    "    'trapezius_EMG_Activity', 'trapezius_EMG_Onsets',\n",
    "    'trapezius_EMG_Offsets', 'zygomaticus_EMG_Clean',\n",
    "    'zygomaticus_EMG_Amplitude', 'zygomaticus_EMG_Activity',\n",
    "    'zygomaticus_EMG_Onsets', 'zygomaticus_EMG_Offsets',\n",
    "    'RSP_RVT', 'RSP_Phase', 'RSP_Phase_Completion',\n",
    "    'RSP_Symmetry_PeakTrough', 'RSP_Symmetry_RiseDecay','skt',\n",
    "    #'sub_num','vid_num',\n",
    "]\n",
    "\n",
    "fizz_columns_of_interest = [ \n",
    "    'PPG_Rate', \n",
    "    'ECG_Rate','ECG_Quality',\n",
    "    'EDA_Clean', 'EDA_Tonic', 'EDA_Phasic', 'SCR_Onsets', 'SCR_Peaks','SCR_Height', 'SCR_Amplitude',\n",
    "    'RSP_Amplitude', 'RSP_Rate',\n",
    "    'corrugator_EMG_Clean',\n",
    "    'corrugator_EMG_Amplitude', 'corrugator_EMG_Activity',\n",
    "    'corrugator_EMG_Onsets', 'corrugator_EMG_Offsets',\n",
    "    'trapezius_EMG_Clean', 'trapezius_EMG_Amplitude',\n",
    "    'trapezius_EMG_Activity', 'trapezius_EMG_Onsets',\n",
    "    'trapezius_EMG_Offsets', 'zygomaticus_EMG_Clean',\n",
    "    'zygomaticus_EMG_Amplitude', 'zygomaticus_EMG_Activity',\n",
    "    'zygomaticus_EMG_Onsets', 'zygomaticus_EMG_Offsets',\n",
    "    'RSP_RVT', 'RSP_Phase', 'RSP_Phase_Completion',\n",
    "    'RSP_Symmetry_PeakTrough', 'RSP_Symmetry_RiseDecay','skt',\n",
    "    # 'sub_num',\n",
    "    # 'vid_num',\n",
    "]\n",
    "\n",
    "fizz_columns_of_interest_no_emg = [ \n",
    "    'PPG_Rate', \n",
    "    'ECG_Rate','ECG_Quality',\n",
    "    'EDA_Clean', 'EDA_Tonic', 'EDA_Phasic', 'SCR_Onsets', 'SCR_Peaks','SCR_Height', 'SCR_Amplitude',\n",
    "    'RSP_Amplitude', 'RSP_Rate',\n",
    "    'RSP_RVT', 'RSP_Phase', 'RSP_Phase_Completion',\n",
    "    'RSP_Symmetry_PeakTrough', 'RSP_Symmetry_RiseDecay','skt',\n",
    "    # 'sub_num',\n",
    "    # 'vid_num',\n",
    "]\n",
    "\n",
    "fizz_columns_of_interest_no_emg_sub_vid = [ \n",
    "    'PPG_Rate', \n",
    "    'ECG_Rate','ECG_Quality',\n",
    "    'EDA_Clean', 'EDA_Tonic', 'EDA_Phasic', 'SCR_Onsets', 'SCR_Peaks','SCR_Height', 'SCR_Amplitude',\n",
    "    'RSP_Amplitude', 'RSP_Rate',\n",
    "    'RSP_RVT', 'RSP_Phase', 'RSP_Phase_Completion',\n",
    "    'RSP_Symmetry_PeakTrough', 'RSP_Symmetry_RiseDecay','skt',\n",
    "    'sub_num',\n",
    "    'vid_num',\n",
    "]\n",
    "\n",
    "fizz_columns_of_interest_sub_vid = [ \n",
    "    'PPG_Rate', \n",
    "    'ECG_Rate','ECG_Quality',\n",
    "    'EDA_Clean', 'EDA_Tonic', 'EDA_Phasic', 'SCR_Onsets', 'SCR_Peaks','SCR_Height', 'SCR_Amplitude',\n",
    "    'RSP_Amplitude', 'RSP_Rate',\n",
    "    'corrugator_EMG_Clean',\n",
    "    'corrugator_EMG_Amplitude', 'corrugator_EMG_Activity',\n",
    "    'corrugator_EMG_Onsets', 'corrugator_EMG_Offsets',\n",
    "    'trapezius_EMG_Clean', 'trapezius_EMG_Amplitude',\n",
    "    'trapezius_EMG_Activity', 'trapezius_EMG_Onsets',\n",
    "    'trapezius_EMG_Offsets', 'zygomaticus_EMG_Clean',\n",
    "    'zygomaticus_EMG_Amplitude', 'zygomaticus_EMG_Activity',\n",
    "    'zygomaticus_EMG_Onsets', 'zygomaticus_EMG_Offsets',\n",
    "    'RSP_RVT', 'RSP_Phase', 'RSP_Phase_Completion',\n",
    "    'RSP_Symmetry_PeakTrough', 'RSP_Symmetry_RiseDecay','skt',\n",
    "    'sub_num',\n",
    "    'vid_num',\n",
    "]\n",
    "\n",
    "zipped_xs = list(zip(['fizz','fizz-emg','fizz-emg_sub_vid','fizz_sub_vid'],[fizz_columns_of_interest,\n",
    "     fizz_columns_of_interest_no_emg,\n",
    "     fizz_columns_of_interest_no_emg_sub_vid,\n",
    "     fizz_columns_of_interest_sub_vid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code window is a copy of \"pipeline_helper.py\" with minor edits.\n",
    "#Check pipeline helper for additional information.\n",
    "\n",
    "import glob,os\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.signal import resample\n",
    "\n",
    "\n",
    "def get_file_paths(subjects, video_numbers, x_folder, y_folder, file_type = '1hz_zscored'):\n",
    "    x_files = []\n",
    "    y_files = []\n",
    "\n",
    "    for subject in subjects:\n",
    "        for video in video_numbers:\n",
    "            x_pattern = os.path.join(x_folder,\n",
    "                                     f\"sub_{int(subject)}_vid_{int(video)}_resampled_{file_type}.csv\")\n",
    "#             y_pattern = os.path.join(y_folder, f\"sub_{int(subject)}_vid_{int(video)}.csv\")\n",
    "            y_pattern = os.path.join(y_folder, f\"sub_{int(subject)}_vid_{int(video)}_resampled_{file_type}.csv\")\n",
    "            #print(x_pattern)\n",
    "\n",
    "            x_files.extend(glob.glob(x_pattern))\n",
    "            y_files.extend(glob.glob(y_pattern))\n",
    "\n",
    "    return x_files, y_files\n",
    "\n",
    "#cross validation for scenario 1\n",
    "def k_fold_cross_validation_time(subjects, video_numbers, x_folder, y_folder, file_type = '1hz'):\n",
    "    train_x, train_y = get_file_paths(subjects, video_numbers, x_folder+'train/', y_folder+'train/', file_type)\n",
    "    test_x, test_y = get_file_paths(subjects, video_numbers, x_folder+'test/', y_folder+'test/', file_type)\n",
    "\n",
    " \n",
    "    fold_data = [((train_x, train_y), (test_x, test_y))]\n",
    "    return fold_data\n",
    "\n",
    "#cross validation for scenario 2\n",
    "def k_fold_cross_validation(subjects, video_numbers, k, x_folder, y_folder, file_type = '1hz_zscored'):\n",
    "    subject_indices = np.arange(len(subjects))\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_data = []\n",
    "    for train_index, test_index in kf.split(subject_indices):\n",
    "        train_subjects = subjects[train_index]\n",
    "        test_subjects = subjects[test_index]\n",
    "\n",
    "        train_x, train_y = get_file_paths(train_subjects, video_numbers, x_folder, y_folder, file_type=file_type)\n",
    "        test_x, test_y = get_file_paths(test_subjects, video_numbers, x_folder, y_folder,  file_type=file_type)\n",
    "\n",
    "        fold_data.append(((train_x, train_y), (test_x, test_y)))\n",
    "\n",
    "    return fold_data\n",
    "\n",
    "#cross validation for scenario 3 and 4\n",
    "def k_fold_cross_validation_video(subjects, video_numbers, k, x_folder, y_folder, file_type = '1hz_zscored'):\n",
    "    video_indices = np.arange(len(video_numbers))\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "    fold_data = []\n",
    "    for train_index, test_index in kf.split(video_indices):\n",
    "        train_videos = video_numbers[train_index]\n",
    "        test_videos = video_numbers[test_index]\n",
    "\n",
    "        train_x, train_y = get_file_paths(subjects, train_videos, x_folder, y_folder, file_type=file_type)\n",
    "        test_x, test_y = get_file_paths(subjects, test_videos, x_folder, y_folder, file_type=file_type)\n",
    "\n",
    "        fold_data.append(((train_x, train_y), (test_x, test_y)))\n",
    "\n",
    "    return fold_data\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class EmognitionDataset(Dataset):\n",
    "    def __init__(self, x_files, y_files, x_columns=None, y_columns=None, downsampling_factor_x=1,downsampling_factor_y=1, upsample_factor_x=1, upsample_factor_y=1):\n",
    "        self.x_data = []\n",
    "        self.y_data = []  \n",
    "        self.sub_num_data = []\n",
    "        self.vid_num_data = []\n",
    "\n",
    "        for file in x_files:\n",
    "            x_df = pd.read_csv(file)\n",
    "            x_array = x_df[x_columns].values[::downsampling_factor_x]\n",
    "            if x_array.shape[0] == 1:\n",
    "                x_array = np.nan_to_num(x_array)\n",
    "            \n",
    "            if upsample_factor_x > 1:\n",
    "                x_array = self.upsample(x_array, upsample_factor_x)\n",
    "            \n",
    "            self.x_data.append(x_array)\n",
    "\n",
    "            sub_num_array = x_df['sub_num'].values[::downsampling_factor_x]\n",
    "            vid_num_array = x_df['vid_num'].values[::downsampling_factor_x]\n",
    "            \n",
    "            if upsample_factor_x > 1:\n",
    "                new_num_samples = sub_num_array.shape[0] * upsample_factor_x\n",
    "                sub_num_array = resample(sub_num_array, new_num_samples)\n",
    "                vid_num_array = resample(vid_num_array, new_num_samples)\n",
    "            \n",
    "            self.sub_num_data.append(sub_num_array)\n",
    "            self.vid_num_data.append(vid_num_array)\n",
    "     \n",
    "\n",
    "        for file in y_files:\n",
    "            y_df = pd.read_csv(file, usecols=y_columns)\n",
    "            y_array = y_df.values[::downsampling_factor_y]\n",
    "            \n",
    "            if upsample_factor_y > 1:\n",
    "                new_num_samples = y_array.shape[0] * upsample_factor_y\n",
    "                if y_array.shape[0] == 1:\n",
    "                     y_array = resample(y_array, new_num_samples)\n",
    "                else:\n",
    "                    y_array = resample(y_array.squeeze(), new_num_samples)\n",
    "            \n",
    "            self.y_data.append(y_array)\n",
    "            \n",
    "        for i in range(len(self.x_data)):\n",
    "            # make sure they are the same length between x_file and y_files\n",
    "#             if upsample_factor_y > 1:\n",
    "#                 print(len(self.x_data[i]), len(self.y_data[i]))\n",
    "            min_len = min(len(self.x_data[i]), len(self.y_data[i]))\n",
    "            self.x_data[i] = self.x_data[i][:min_len]\n",
    "            self.y_data[i] = self.y_data[i][:min_len]\n",
    "            self.sub_num_data[i] = self.sub_num_data[i][:min_len]\n",
    "            self.vid_num_data[i] = self.vid_num_data[i][:min_len]\n",
    "\n",
    "            \n",
    "            # Combine x and y data, drop rows with NaN values\n",
    "            combined_df = pd.concat([pd.DataFrame(self.x_data[i], columns=x_columns),\n",
    "                         pd.DataFrame(self.y_data[i], columns=y_columns),\n",
    "                         pd.DataFrame(self.sub_num_data[i], columns=['sub_num_dataset']),\n",
    "                         pd.DataFrame(self.vid_num_data[i], columns=['vid_num_dataset'])], axis=1)\n",
    "\n",
    "            # Drop rows with NaN values\n",
    "            combined_df = combined_df.dropna()\n",
    "\n",
    "            # Extract cleaned x, y, sub_num, and vid_num data\n",
    "            self.x_data[i] = combined_df[x_columns].values\n",
    "            self.y_data[i] = combined_df[y_columns].values\n",
    "            self.sub_num_data[i] = combined_df['sub_num_dataset'].values\n",
    "            self.vid_num_data[i] = combined_df['vid_num_dataset'].values\n",
    "  \n",
    "    def upsample(self, x_array, upsample_factor_x):\n",
    "        if x_array.shape[0] > 1:\n",
    "            new_num_samples = x_array.shape[0] * upsample_factor_x\n",
    "            col_mean = np.nanmean(x_array, axis=0)\n",
    "            inds = np.where(np.isnan(x_array))\n",
    "            x_array[inds] = np.take(col_mean, inds[1])\n",
    "            x_array = resample(x_array.squeeze(), new_num_samples)\n",
    "        elif x_array.shape[0] == 1 or x_array.ndim == 1:\n",
    "            new_num_samples = x_array.shape[0] * upsample_factor_x\n",
    "            col_mean = np.nanmean(x_array, axis=0)\n",
    "            inds = np.where(np.isnan(x_array))\n",
    "            x_array[inds] = np.take(col_mean, inds[1])\n",
    "            x_array = resample(x_array, new_num_samples)\n",
    "        return x_array\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x_data[index]\n",
    "        y = self.y_data[index]\n",
    "        sub_num = self.sub_num_data[index]\n",
    "        vid_num = self.vid_num_data[index]\n",
    "\n",
    "        return x, y, sub_num, vid_num\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib\n",
    "from math import sqrt\n",
    "from scipy.signal import resample\n",
    "\n",
    "#upsample the predictions from X hz to Y hz\n",
    "def upsample_predictions(predictions, factor):\n",
    "    \"\"\"\n",
    "    Upsample the predictions by a given factor using resample function.\n",
    "    \n",
    "    :param predictions: np.array of predictions\n",
    "    :param factor: int, factor to upsample the predictions\n",
    "    :return: np.array of upsampled predictions\n",
    "    \"\"\"\n",
    "    new_num_samples = predictions.shape[0] * factor\n",
    "    upsampled_predictions = resample(predictions.squeeze(), new_num_samples)\n",
    "    \n",
    "    return upsampled_predictions.reshape(-1, 1)\n",
    "\n",
    "def TrainModel(model, fold_data, x_columns, y_columns, save_file_name, \n",
    "                        downsampling_factor_y=1, \n",
    "                        downsampling_factor_x=1,verbose = True):\n",
    "    '''\n",
    "    which_features: x column names\n",
    "    which_y: y column name\n",
    "    save_file_name: descriptive name for the specific version of this model.\n",
    "    e.g., LinearReg_arousal_\n",
    "    \n",
    "    '''\n",
    "    test_res = []\n",
    "    all_pred_y = []\n",
    "    all_sub_num = []\n",
    "    all_vid_num = []\n",
    "    for f, fold in enumerate(fold_data):\n",
    "        train_x_files, train_y_files = fold[0]\n",
    "        test_x_files, test_y_files = fold[1]\n",
    "\n",
    "        train_dataset = EmognitionDataset(\n",
    "            train_x_files, train_y_files, x_columns=x_columns, y_columns=y_columns,\n",
    "            downsampling_factor_y=downsampling_factor_y,\n",
    "            downsampling_factor_x=downsampling_factor_x\n",
    "        )\n",
    "        \n",
    "        test_dataset = EmognitionDataset(\n",
    "            test_x_files, test_y_files, x_columns=x_columns, y_columns=y_columns,\n",
    "            downsampling_factor_y=downsampling_factor_y,\n",
    "            downsampling_factor_x=downsampling_factor_x, upsample_factor_x=20, upsample_factor_y=20\n",
    "        )\n",
    "    \n",
    "\n",
    "        train_x = np.vstack([train_dataset[i][0] for i in range(len(train_dataset))])\n",
    "        train_y = np.vstack([train_dataset[i][1] for i in range(len(train_dataset))])\n",
    "\n",
    "        test_x = np.vstack([test_dataset[i][0] for i in range(len(test_dataset))])\n",
    "        test_y = np.vstack([test_dataset[i][1] for i in range(len(test_dataset))])\n",
    "        #print([test_dataset[i][2] for i in range(len(test_dataset))])\n",
    "        test_sub = np.hstack([test_dataset[i][2] for i in range(len(test_dataset))])\n",
    "        test_vid = np.hstack([test_dataset[i][3] for i in range(len(test_dataset))])\n",
    "\n",
    "        \n",
    "        model.fit(train_x, train_y)\n",
    "\n",
    "       # Make predictions\n",
    "        pred_y = model.predict(test_x).reshape(-1, 1)\n",
    "        \n",
    "\n",
    "        # Calculate metrics with upsampled predictions\n",
    "        rmse = sqrt(mean_squared_error(test_y, pred_y))\n",
    "        test_res.append(rmse)\n",
    "        r2 = r2_score(test_y, pred_y)\n",
    "        \n",
    "        \n",
    "        if verbose:\n",
    "            print(f'---------------------- fold {f+1} ---------------------------')\n",
    "            print(f'rmse = {rmse:.3f}')\n",
    "            print(f'r2 score = {r2:.3f}')\n",
    "\n",
    "        # save: \n",
    "        all_pred_y.append(pred_y)\n",
    "        all_sub_num.append(test_sub)\n",
    "        all_vid_num.append(test_vid)\n",
    "\n",
    "  #  return all_pred_y\n",
    "    all_pred_y_concat = np.vstack(all_pred_y)\n",
    "    all_sub_num_concat = np.hstack(all_sub_num)\n",
    "    all_vid_num_concat = np.hstack(all_vid_num)\n",
    "\n",
    "    all_pred_y_df = pd.DataFrame({'sub': all_sub_num_concat, 'vid': all_vid_num_concat, 'pred_y': all_pred_y_concat[:,0]})\n",
    "    all_pred_y_df.to_csv(save_file_name + '.csv', index=False)\n",
    "\n",
    "\n",
    "    joblib.dump(model, save_file_name + '.joblib')\n",
    "    return test_res, all_pred_y_df, model\n",
    "\n",
    "def train_model_no_eval(model, \n",
    "                        train_x_files,\n",
    "                        train_y_files,\n",
    "                        x_columns, \n",
    "                        y_columns, \n",
    "                        save_file_name, \n",
    "                        downsampling_factor_y=20, \n",
    "                        downsampling_factor_x=1, \n",
    "                        verbose = True):\n",
    "    '''\n",
    "    which_features: x column names\n",
    "    which_y: y column name\n",
    "    save_file_name: descriptive name for the specific version of this model.\n",
    "    e.g., LinearReg_arousal_\n",
    "    \n",
    "    '''\n",
    "    train_x_files, train_y_files\n",
    "\n",
    "    train_dataset = EmognitionDataset(\n",
    "        train_x_files, \n",
    "        train_y_files,\n",
    "        x_columns=x_columns,\n",
    "        y_columns=y_columns,\n",
    "        downsampling_factor_y=downsampling_factor_y,\n",
    "        downsampling_factor_x=downsampling_factor_x\n",
    "    )\n",
    "\n",
    "    train_x = np.vstack([train_dataset[i][0] for i in range(len(train_dataset))])\n",
    "    train_y = np.vstack([train_dataset[i][1] for i in range(len(train_dataset))])\n",
    "    model.fit(train_x, train_y)\n",
    "    joblib.dump(model, save_file_name + '.joblib')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is designed to perform model training and evaluation for each scenario.\n",
    "\n",
    "For instance, for scenario 2:\n",
    "\n",
    "1. It initializes a list of models (`models`) and their corresponding names (`model_names`). It uses Elastic Net, Random Forest, and Support Vector Regression with Radial basis function (RBF) kernel.\n",
    "\n",
    "2. It sets up a list of target variables (`y_columns_list`) for arousal and valence.\n",
    "\n",
    "3. It specifies the scenario number as 2 and iterates over the target variables in `y_columns_list`.\n",
    "\n",
    "4. It iterates over the file type (in this case, '1hz') and the models in the `models` list along with their names in the `model_names` list.\n",
    "\n",
    "5. Inside the loop, it iterates over the folds (0 to 4) for Scenario 2 and loads the subject numbers and video numbers for each fold.\n",
    "\n",
    "6. It sets up the file paths for the input physiological data (`x_folder`) and the annotation data (`y_folder`).\n",
    "\n",
    "7. It performs k-fold cross-validation with the given input data and parameters. The `TrainModel` function is called to train the model using the specified input features and target variables.\n",
    "\n",
    "8. It calculates the Root Mean Squared Error (RMSE) for each fold and stores the results in a list (`rmses`).\n",
    "\n",
    "9. It saves the results to a CSV file, which includes the fold number, input feature type, and the RMSE for each fold.\n",
    "\n",
    "In summary, this code trains and evaluates several models (Elastic Net, Random Forest, and Support Vector Regression with RBF kernel) using k-fold cross-validation on the input physiological data and target variables (arousal and valence) for Scenario 2 of the Emognition 2023 challenge. The performance results are saved to CSV files for further analysis.\n",
    "\n",
    "Each scenario works in a similar way in terms of the code structure. However, scenarios differs in calling different cross validation functions, different features, and different machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCENARIO2 \n",
    "\n",
    "y_columns_list = [['arousal'],['valence']]\n",
    "#y_columns_list = [['valence']]\n",
    "models = []\n",
    "model_names = []\n",
    "# specify the model\n",
    "models.append(linear_model.ElasticNet())\n",
    "model_names.append('Elastic_Net')\n",
    "\n",
    "models.append(ensemble.RandomForestRegressor())\n",
    "model_names.append('random_forest_default')\n",
    "\n",
    "models.append(svm.SVR(kernel='rbf'))\n",
    "model_names.append('SVR_RBF')\n",
    "\n",
    "\n",
    "\n",
    "# specify the data info\n",
    "scenario = 2\n",
    "\n",
    "# where to save the results:\n",
    "# TO DO: add which Features in the save_file_name to test features....\n",
    "for y_columns in y_columns_list:\n",
    "    for file_type in ['1hz']:\n",
    "        for model_name, model in list(zip(model_names,models)):\n",
    "            print(model_name)\n",
    "            fold_arr,x_names, rmses =[],[],[]\n",
    "            for fold_num in range(0,5):\n",
    "                print('folder ', fold_num)\n",
    "                for x_name,x_cols in zipped_xs: \n",
    "                    save_file_name = f'/work/abslab/emognition_2023_challenge/results/results_30s/scenario_{scenario}/fold_{fold_num}/{model_name}_{y_columns[0]}_{x_name}'\n",
    "\n",
    "                    subjects = np.loadtxt(f'/work/abslab/emognition_2023_challenge/tests/scenario_{scenario}_fold_{fold_num}_sub_list.txt')  # Subject numbers\n",
    "                    video_numbers = np.loadtxt(f'/work/abslab/emognition_2023_challenge/tests/scenario_{scenario}_fold_{fold_num}_video_list.txt')  # Video numbers\n",
    "                    k = 5  # Number of folds\n",
    "\n",
    "                    x_folder = f\"/work/abslab/emognition_2023_challenge/file_prep_30sec/scenario_{scenario}/fold_{fold_num}/train/physiology\"\n",
    "                    y_folder = f\"/work/abslab/emognition_2023_challenge/file_prep_30sec/scenario_{scenario}/fold_{fold_num}/train/annotations\"\n",
    "\n",
    "                    # x_files, y_files = get_file_paths(subjects, video_numbers, x_folder, y_folder)\n",
    "                    fold_data = k_fold_cross_validation(subjects,\n",
    "                                                                              video_numbers,\n",
    "                                                                              k, \n",
    "                                                                              x_folder,\n",
    "                                                                              y_folder, \n",
    "                                                                              file_type)\n",
    "            \n",
    "                    rmse_list,_,_ = TrainModel(model,fold_data,x_cols,y_columns,save_file_name,\n",
    "                                                                              verbose=False)\n",
    "                    fold_arr.append(fold_num),x_names.append(x_name),rmses.append(np.mean(rmse_list))\n",
    "\n",
    "            pd.DataFrame({'folds':fold_arr,'x_col_type':x_names,\n",
    "                          'rmses':rmses}).to_csv(\n",
    "                f'/work/abslab/emognition_2023_challenge/results/results_30s/scenario_{scenario}_{model_name}_across_folds_{y_columns[0]}_{file_type}.csv')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCENARIO3\n",
    "\n",
    "y_columns_list = [['arousal'],['valence']]\n",
    "#y_columns_list = [['valence']]\n",
    "models = []\n",
    "model_names = []\n",
    "# specify the model\n",
    "models.append(linear_model.ElasticNet())\n",
    "model_names.append('Elastic_Net')\n",
    "\n",
    "models.append(ensemble.RandomForestRegressor())\n",
    "model_names.append('random_forest_default')\n",
    "\n",
    "models.append(svm.SVR(kernel='rbf'))\n",
    "model_names.append('SVR_RBF')\n",
    "\n",
    "# model = linear_model.LinearRegression()\n",
    "# model_name = 'LinearReg'\n",
    "\n",
    "\n",
    "# specify the data info\n",
    "scenario = 3\n",
    "\n",
    "# where to save the results:\n",
    "# TO DO: add which Features in the save_file_name to test features....\n",
    "for y_columns in y_columns_list:\n",
    "    for file_type in ['1hz']:\n",
    "        for model_name, model in list(zip(model_names,models)):\n",
    "            print(model_name)\n",
    "            fold_arr,x_names, rmses =[],[],[]\n",
    "            for fold_num in range(0,4):\n",
    "                print('folder ', fold_num)\n",
    "                for x_name,x_cols in zipped_xs: \n",
    "                    save_file_name = f'/work/abslab/emognition_2023_challenge/results/results_30s/scenario_{scenario}/fold_{fold_num}/{model_name}_{y_columns[0]}_{x_name}'\n",
    "\n",
    "                    subjects = np.loadtxt(f'/work/abslab/emognition_2023_challenge/tests/scenario_{scenario}_fold_{fold_num}_sub_list.txt')  # Subject numbers\n",
    "                    video_numbers = np.loadtxt(f'/work/abslab/emognition_2023_challenge/tests/scenario_{scenario}_fold_{fold_num}_video_list.txt')  # Video numbers\n",
    "                    k = 4  # Number of folds\n",
    "\n",
    "                    x_folder = f\"/work/abslab/emognition_2023_challenge/file_prep_30sec/scenario_{scenario}/fold_{fold_num}/train/physiology\"\n",
    "                    y_folder = f\"/work/abslab/emognition_2023_challenge/file_prep_30sec/scenario_{scenario}/fold_{fold_num}/train/annotations\"\n",
    "\n",
    "                    # x_files, y_files = get_file_paths(subjects, video_numbers, x_folder, y_folder)\n",
    "                    fold_data = k_fold_cross_validation_video(subjects,\n",
    "                                                                              video_numbers,\n",
    "                                                                              k, \n",
    "                                                                              x_folder,\n",
    "                                                                              y_folder, \n",
    "                                                                              file_type)\n",
    "            \n",
    "                    rmse_list,_,_ = TrainModel(model,fold_data,x_cols,y_columns,save_file_name,\n",
    "                                                                              verbose=False)\n",
    "                    fold_arr.append(fold_num),x_names.append(x_name),rmses.append(np.mean(rmse_list))\n",
    "\n",
    "            pd.DataFrame({'folds':fold_arr,'x_col_type':x_names,\n",
    "                          'rmses':rmses}).to_csv(\n",
    "                f'/work/abslab/emognition_2023_challenge/results/results_30s/scenario_{scenario}_{model_name}_across_folds_{y_columns[0]}_{file_type}.csv')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SCENARIO4\n",
    "\n",
    "y_columns_list = [['arousal'],['valence']]\n",
    "#y_columns_list = [['valence']]\n",
    "models = []\n",
    "model_names = []\n",
    "# specify the model\n",
    "models.append(linear_model.ElasticNet())\n",
    "model_names.append('Elastic_Net')\n",
    "\n",
    "models.append(ensemble.RandomForestRegressor())\n",
    "model_names.append('random_forest_default')\n",
    "\n",
    "models.append(svm.SVR(kernel='rbf'))\n",
    "model_names.append('SVR_RBF')\n",
    "\n",
    "# model = linear_model.LinearRegression()\n",
    "# model_name = 'LinearReg'\n",
    "\n",
    "\n",
    "# specify the data info\n",
    "scenario = 4\n",
    "\n",
    "# where to save the results:\n",
    "# TO DO: add which Features in the save_file_name to test features....\n",
    "for y_columns in y_columns_list:\n",
    "    for file_type in ['1hz']:\n",
    "        for model_name, model in list(zip(model_names,models)):\n",
    "            print(model_name)\n",
    "            fold_arr,x_names, rmses =[],[],[]\n",
    "            for fold_num in range(0,2):\n",
    "                print('folder ', fold_num)\n",
    "                for x_name,x_cols in zipped_xs: \n",
    "                    save_file_name = f'/work/abslab/emognition_2023_challenge/results/results_30s/scenario_{scenario}/fold_{fold_num}/{model_name}_{y_columns[0]}_{x_name}'\n",
    "\n",
    "                    subjects = np.loadtxt(f'/work/abslab/emognition_2023_challenge/tests/scenario_{scenario}_fold_{fold_num}_sub_list.txt')  # Subject numbers\n",
    "                    video_numbers = np.loadtxt(f'/work/abslab/emognition_2023_challenge/tests/scenario_{scenario}_fold_{fold_num}_video_list.txt')  # Video numbers\n",
    "                    k = 2  # Number of folds\n",
    "\n",
    "                    x_folder = f\"/work/abslab/emognition_2023_challenge/file_prep_30sec/scenario_{scenario}/fold_{fold_num}/train/physiology\"\n",
    "                    y_folder = f\"/work/abslab/emognition_2023_challenge/file_prep_30sec/scenario_{scenario}/fold_{fold_num}/train/annotations\"\n",
    "\n",
    "                    # x_files, y_files = get_file_paths(subjects, video_numbers, x_folder, y_folder)\n",
    "                    fold_data = k_fold_cross_validation_video(subjects,\n",
    "                                                                              video_numbers,\n",
    "                                                                              k, \n",
    "                                                                              x_folder,\n",
    "                                                                              y_folder, \n",
    "                                                                              file_type)\n",
    "            \n",
    "                    rmse_list,_,_ = TrainModel(model,fold_data,x_cols,y_columns,save_file_name,\n",
    "                                                                              verbose=False)\n",
    "                    fold_arr.append(fold_num),x_names.append(x_name),rmses.append(np.mean(rmse_list))\n",
    "\n",
    "            pd.DataFrame({'folds':fold_arr,'x_col_type':x_names,\n",
    "                          'rmses':rmses}).to_csv(\n",
    "                f'/work/abslab/emognition_2023_challenge/results/results_30s/scenario_{scenario}_{model_name}_across_folds_{y_columns[0]}_{file_type}.csv')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #PRE-SCENARIO 1\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import glob\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # creating cv data for scenario 1 for 1hz\n",
    "# # this do not resample the y files\n",
    "# x_data_path = f\"/work/abslab/emognition_2023_challenge/file_prep_30sec/scenario_1/train/physiology/\"\n",
    "# y_data_path = f\"/work/abslab/emognition_2023_challenge/data/scenario_1/train/annotations/\"\n",
    "# s_data_path = f\"/work/abslab/emognition_2023_challenge/file_prep_30sec/scenario_1/train/\"\n",
    "\n",
    "\n",
    "# video_numbers = np.loadtxt(\"/work/abslab/emognition_2023_challenge/data/scenario_1/train/video_list.txt\")\n",
    "# subjects = np.loadtxt(\"/work/abslab/emognition_2023_challenge/data/scenario_1/train/sub_list.txt\")\n",
    "\n",
    "# file_pattern = '1hz'\n",
    "# for v in video_numbers:  \n",
    "#     print(int(v))\n",
    "  \n",
    "#     all_files = glob.glob(f'/work/abslab/emognition_2023_challenge/data/scenario_1/train/annotations/*vid_{int(v)}.csv')\n",
    "#     this_df = pd.read_csv(all_files[1])\n",
    "#     video_length = len(this_df['time'])\n",
    "\n",
    "#     test_size = 601/(video_length + 601)\n",
    "\n",
    "#     x_files, y_files = get_file_paths(subjects, [v], x_data_path, y_data_path, file_pattern)\n",
    "    \n",
    "#     for i in range(len(x_files)):\n",
    "\n",
    "#         X = pd.read_csv(x_files[i])\n",
    "#         y = pd.read_csv(y_files[i])\n",
    "#         y_ = pd.DataFrame()\n",
    "        \n",
    "#         for i in range(len(X)):\n",
    "#             t = X.iloc[i,0]\n",
    "#             newy = y.loc[y['time'] == t]\n",
    "#             y_ = y_.append(newy)\n",
    "\n",
    "#         file = y_files[i]\n",
    "#         vid_id = file.split('vid_')[1].split('.csv')[0]\n",
    "\n",
    "#         sub_id = file.split('sub_')[1].split('_vid')[0]\n",
    "        \n",
    "#         train_x, test_x, train_y, test_y = train_test_split(X, y_, test_size=test_size, shuffle=False)\n",
    "        \n",
    "#         train_x.to_csv(s_data_path + f'cv/train/sub_{sub_id}_vid_{vid_id}_resampled_{file_pattern}')\n",
    "#         test_x.to_csv(s_data_path + f'cv/test/sub_{sub_id}_vid_{vid_id}_resampled_{file_pattern}')\n",
    "\n",
    "\n",
    "\n",
    "# #SCENARIO 1\n",
    "\n",
    "\n",
    "# y_columns_list = [['arousal'],['valence']]\n",
    "# #y_columns_list = [['valence']]\n",
    "# models = []\n",
    "# model_names = []\n",
    "# # specify the model\n",
    "# models.append(linear_model.ElasticNet())\n",
    "# model_names.append('Elastic_Net')\n",
    "\n",
    "# models.append(ensemble.RandomForestRegressor())\n",
    "# model_names.append('random_forest_default')\n",
    "\n",
    "# models.append(svm.SVR(kernel='rbf'))\n",
    "# model_names.append('SVR_RBF')\n",
    "\n",
    "# # model = linear_model.LinearRegression()\n",
    "# # model_name = 'LinearReg'\n",
    "\n",
    "\n",
    "# # specify the data info\n",
    "# scenario = 1\n",
    "\n",
    "# # where to save the results:\n",
    "# # TO DO: add which Features in the save_file_name to test features....\n",
    "# for y_columns in y_columns_list:\n",
    "#     for file_type in ['1hz']:\n",
    "#         for model_name, model in list(zip(model_names,models)):\n",
    "#             print(model_name)\n",
    "#             x_names, rmses =[],[]\n",
    "#             for x_name,x_cols in zipped_xs: \n",
    "#                 save_file_name = f'/work/abslab/emognition_2023_challenge/results/results_30s/scenario_{scenario}/{model_name}_{y_columns[0]}_{x_name}'\n",
    "\n",
    "#                 subjects = np.loadtxt(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/train/sub_list.txt')  # Subject numbers\n",
    "#                 video_numbers = np.loadtxt(f'/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/train/video_list.txt')  # Video numbers\n",
    "#                 #k = 1  # Number of folds\n",
    "\n",
    "#                 x_folder = f\"/work/abslab/emognition_2023_challenge/file_prep_30sec/scenario_{scenario}/train/physiology\"\n",
    "#                 y_folder = f\"/work/abslab/emognition_2023_challenge/data/scenario_{scenario}/train/annotations\"\n",
    "#                 s_folder = f\"/work/abslab/emognition_2023_challenge/file_prep_30sec/scenario_1/train/cv/\"\n",
    "\n",
    "                \n",
    "#                     # x_files, y_files = get_file_paths(subjects, video_numbers, x_folder, y_folder)\n",
    "              \n",
    "#                 train_x, train_y = get_file_paths(subjects, video_numbers, s_folder+'train/', y_folder+'train/', file_type)\n",
    "#                 test_x, test_y = get_file_paths(subjects, video_numbers, s_folder+'test/', y_folder+'test/', file_type)\n",
    "\n",
    " \n",
    "#                 fold_data = k_fold_cross_validation_time[((train_x, train_y), (test_x, test_y))]\n",
    "\n",
    "                    \n",
    "                    \n",
    "            \n",
    "#                 rmse_list,_,_ = TrainModel(model,fold_data,x_cols,y_columns,save_file_name,\n",
    "#                                                                               verbose=False)\n",
    "#                 x_names.append(x_name),rmses.append(np.mean(rmse_list))\n",
    "\n",
    "#             pd.DataFrame({'x_col_type':x_names,\n",
    "#                               'rmses':rmses}).to_csv(\n",
    "#                     f'/work/abslab/emognition_2023_challenge/results/results_30s/scenario_{scenario}_{model_name}_{y_columns[0]}_{file_type}.csv')      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
